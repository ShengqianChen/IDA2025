import os

# chroma ä¸ä¸Šä¼ æ•°æ®
os.environ["ANONYMIZED_TELEMETRY"] = "false"
os.environ["DISABLE_TELEMETRY"] = "1"
os.environ["CHROMA_TELEMETRY_ENABLED"] = "false"

import json
import logging
import pandas as pd
import re
from typing import Any, Dict, List
from enum import Enum

# langchain
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
from langchain_ollama import OllamaLLM, OllamaEmbeddings

# llama-index & chroma
import chromadb
from llama_index.core import Settings  # å…¨å±€
from llama_index.core import Document
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore  # æ³¨æ„å¯¼å…¥è·¯å¾„

# å¯¼å…¥é¢†åŸŸçŸ¥è¯†
from domain_knowledge import (
    get_error_code_meaning, 
    get_service_dependencies, 
    get_fault_category,
    get_severity_level,
    get_common_pattern_info,
    get_monitoring_recommendations,
    get_expert_insights,
    get_industry_standards,
    get_best_practices,
    FAULT_CATEGORIES,
    COMMON_PATTERNS
)

# æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ConversationType(Enum):
    """å¯¹è¯ç±»å‹æšä¸¾"""
    FAULT_ANALYSIS = "fault_analysis"        # æ•…éšœåˆ†æï¼ˆMarkdownæ ¼å¼ï¼‰
    GENERAL_QUESTION = "general_question"    # ä¸€èˆ¬é—®é¢˜ï¼ˆMarkdownæ ¼å¼ï¼‰
    FOLLOW_UP_QUESTION = "follow_up"         # è·Ÿè¿›é—®é¢˜ï¼ˆMarkdownæ ¼å¼ï¼‰
    EXPLANATION_REQUEST = "explanation"       # è§£é‡Šè¯·æ±‚ï¼ˆMarkdownæ ¼å¼ï¼‰
    PREVENTION_QUESTION = "prevention"       # é¢„é˜²æªæ–½ï¼ˆMarkdownæ ¼å¼ï¼‰
    DEPENDENCY_QUESTION = "dependency"       # ä¾èµ–å…³ç³»ï¼ˆMarkdownæ ¼å¼ï¼‰


class TopKLogSystem:
    def __init__(
            self,
            log_path: str,
            llm: str,
            embedding_model: str,
    ) -> None:
        # init models
        self.embedding_model = OllamaEmbeddings(model=embedding_model)

        self.llm = OllamaLLM(model=llm, temperature=0.1)

        # init database
        Settings.llm = self.llm
        Settings.embed_model = self.embedding_model  # å…¨å±€è®¾ç½®

        self.log_path = log_path
        self.log_index = None
        self.vector_store = None
        self._build_vectorstore()  # ç›´æ¥æ„å»º

    # åŠ è½½æ•°æ®å¹¶æ„å»ºç´¢å¼•
    def _build_vectorstore(self):
        vector_store_path = "./data/vector_stores"
        os.makedirs(vector_store_path, exist_ok=True)  # exist_ok=True ç›®å½•å­˜åœ¨æ—¶ä¸æŠ¥é”™

        chroma_client = chromadb.PersistentClient(path=vector_store_path)  # chromadb æŒä¹…åŒ–

        # ChromaVectorStore å°† collection ä¸ store ç»‘å®š
        # ä¹Ÿæ˜¯å°† Chroma åŒ…è£…ä¸º llama-index çš„æ¥å£
        # StorageContextå­˜å‚¨ä¸Šä¸‹æ–‡ï¼Œ åŒ…å« Vector Storeã€Document Storeã€Index Store ç­‰
        log_collection = chroma_client.get_or_create_collection("log_collection")

        # æ„å»º log åº“ index
        log_vector_store = ChromaVectorStore(chroma_collection=log_collection)
        log_storage_context = StorageContext.from_defaults(vector_store=log_vector_store)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç´¢å¼•
        try:
            # å°è¯•ä»ç°æœ‰å­˜å‚¨åŠ è½½ç´¢å¼•
            if log_collection.count() > 0:
                logger.info(f"å‘ç°ç°æœ‰ç´¢å¼•ï¼ŒåŒ…å« {log_collection.count()} æ¡è®°å½•")
                self.log_index = VectorStoreIndex.from_vector_store(
                    log_vector_store,
                    storage_context=log_storage_context,
                    show_progress=True,
                )
                logger.info("æˆåŠŸåŠ è½½ç°æœ‰æ—¥å¿—åº“ç´¢å¼•")
                return
        except Exception as e:
            logger.warning(f"åŠ è½½ç°æœ‰ç´¢å¼•å¤±è´¥: {e}ï¼Œå°†é‡æ–°æ„å»º")
        
        # å¦‚æœä¸å­˜åœ¨ç´¢å¼•æˆ–åŠ è½½å¤±è´¥ï¼Œé‡æ–°æ„å»º
        if log_documents := self._load_documents(self.log_path):
            self.log_index = VectorStoreIndex.from_documents(
                log_documents,
                storage_context=log_storage_context,
                show_progress=True,
            )
            logger.info(f"æ—¥å¿—åº“ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…± {len(log_documents)} æ¡æ—¥å¿—")

    @staticmethod
    # åŠ è½½æ–‡æ¡£æ•°æ®
    def _load_documents(data_path: str) -> List[Document]:
        if not os.path.exists(data_path):
            logger.warning(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
            return []

        documents = []
        for file in os.listdir(data_path):
            ext = os.path.splitext(file)[1]
            if ext not in [".txt", ".md", ".json", ".jsonl", ".csv"]:
                continue

            file_path = f"{data_path}/{file}"
            try:
                if ext == ".csv":  # utf-8 çš„ csv
                    # å¤§å‹ csv åˆ†å—è¿›è¡Œè¯»å–
                    chunk_size = 1000  # æ¯æ¬¡è¯»å–1000è¡Œ
                    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
                        for row in chunk.itertuples(index=False):  # æ— è¡Œå·
                            content = str(row).replace("Pandas", " ")
                            documents.append(Document(text=content))
                else:  # .txt or .md, .json
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        doc = Document(text=content, )
                        documents.append(doc)
            except Exception as e:
                logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥ {file_path}: {e}")
        return documents

        # æ£€ç´¢ç›¸å…³æ—¥å¿—

    def retrieve_logs(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        å¤šç­–ç•¥æ™ºèƒ½æ£€ç´¢æ—¥å¿—
        """
        if not self.log_index:
            return []

        try:
            # ç­–ç•¥1: è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
            semantic_results = self._semantic_retrieval(query, top_k)
            
            # ç­–ç•¥2: å…³é”®è¯ç²¾ç¡®åŒ¹é…
            keyword_results = self._keyword_retrieval(query, top_k)
            
            # ç­–ç•¥3: é”™è¯¯ç åŒ¹é…
            error_code_results = self._error_code_retrieval(query, top_k)
            
            # åˆå¹¶å’Œå»é‡ç»“æœ
            all_results = semantic_results + keyword_results + error_code_results
            filtered_results = self._deduplicate_and_rank(all_results, top_k)
            
            return filtered_results
        except Exception as e:
            logger.error(f"æ—¥å¿—æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _semantic_retrieval(self, query: str, top_k: int) -> List[Dict]:
        """è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢"""
        try:
            retriever = self.log_index.as_retriever(similarity_top_k=top_k)
            results = retriever.retrieve(query)

            formatted_results = []
            for result in results:
                formatted_results.append({
                    "content": result.text,
                    "score": result.score,
                    "retrieval_method": "semantic"
                })
            return formatted_results
        except Exception as e:
            logger.error(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _keyword_retrieval(self, query: str, top_k: int) -> List[Dict]:
        """å…³é”®è¯ç²¾ç¡®åŒ¹é…æ£€ç´¢"""
        try:
            # æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯
            keywords = self._extract_keywords(query)
            if not keywords:
                return []
            
            # ä½¿ç”¨å…³é”®è¯è¿›è¡Œæ£€ç´¢
            keyword_query = " ".join(keywords)
            retriever = self.log_index.as_retriever(similarity_top_k=top_k)
            results = retriever.retrieve(keyword_query)
            
            formatted_results = []
            for result in results:
                # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
                keyword_score = self._calculate_keyword_score(result.text, keywords)
                if keyword_score > 0.3:  # å…³é”®è¯åŒ¹é…é˜ˆå€¼
                    formatted_results.append({
                        "content": result.text,
                        "score": keyword_score,
                        "retrieval_method": "keyword"
                    })
            return formatted_results
        except Exception as e:
            logger.error(f"å…³é”®è¯æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _error_code_retrieval(self, query: str, top_k: int) -> List[Dict]:
        """é”™è¯¯ç ç²¾ç¡®åŒ¹é…æ£€ç´¢"""
        try:
            # æå–æŸ¥è¯¢ä¸­çš„é”™è¯¯ç 
            error_codes = self._extract_error_codes(query)
            if not error_codes:
                return []
            
            # ä½¿ç”¨é”™è¯¯ç è¿›è¡Œæ£€ç´¢
            error_query = " ".join(error_codes)
            retriever = self.log_index.as_retriever(similarity_top_k=top_k)
            results = retriever.retrieve(error_query)
            
            formatted_results = []
            for result in results:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯ç 
                if any(code in result.text for code in error_codes):
                    formatted_results.append({
                        "content": result.text,
                        "score": 1.0,  # ç²¾ç¡®åŒ¹é…ç»™æœ€é«˜åˆ†
                        "retrieval_method": "error_code"
                    })
            return formatted_results
        except Exception as e:
            logger.error(f"é”™è¯¯ç æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _extract_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢å…³é”®è¯"""
        import re
        # æå–ä¸­æ–‡å’Œè‹±æ–‡å…³é”®è¯
        keywords = []
        
        # æå–ä¸­æ–‡è¯æ±‡ï¼ˆ2-4ä¸ªå­—ç¬¦ï¼‰
        chinese_words = re.findall(r'[\u4e00-\u9fff]{2,4}', query)
        keywords.extend(chinese_words)
        
        # æå–è‹±æ–‡è¯æ±‡ï¼ˆ3ä¸ªå­—ç¬¦ä»¥ä¸Šï¼‰
        english_words = re.findall(r'\b[A-Za-z]{3,}\b', query)
        keywords.extend(english_words)
        
        # æå–æŠ€æœ¯æœ¯è¯­
        tech_terms = ['æ•°æ®åº“', 'è¿æ¥æ± ', 'è®¤è¯', 'æ”¯ä»˜', 'åº“å­˜', 'è®¢å•', 'ç”¨æˆ·', 'æœåŠ¡']
        for term in tech_terms:
            if term in query:
                keywords.append(term)
        
        return list(set(keywords))  # å»é‡

    def _calculate_keyword_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°"""
        if not keywords:
            return 0.0
        
        matches = 0
        for keyword in keywords:
            if keyword.lower() in text.lower():
                matches += 1
        
        return matches / len(keywords)

    def _deduplicate_and_rank(self, all_results: List[Dict], top_k: int) -> List[Dict]:
        """å»é‡å’Œæ’åºç»“æœ"""
        # æŒ‰å†…å®¹å»é‡
        seen_contents = set()
        unique_results = []
        
        for result in all_results:
            content_hash = hash(result["content"])
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                unique_results.append(result)
        
        # æŒ‰åˆ†æ•°æ’åº
        unique_results.sort(key=lambda x: x["score"], reverse=True)
        
        # è¿”å›å‰top_kä¸ªç»“æœ
        return unique_results[:top_k]

    def detect_conversation_type(self, query: str, context: str = "") -> ConversationType:
        """
        è¯†åˆ«å¯¹è¯ç±»å‹
        
        Args:
            query: ç”¨æˆ·å½“å‰æŸ¥è¯¢
            context: å¯¹è¯å†å²ä¸Šä¸‹æ–‡
            
        Returns:
            ConversationType: è¯†åˆ«å‡ºçš„å¯¹è¯ç±»å‹
        """
        query_lower = query.lower()
        context_lower = context.lower()
        
        # 1. æ•…éšœåˆ†æç±»é—®é¢˜ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼ŒåŒ…å«é”™è¯¯ç çš„æŸ¥è¯¢ï¼‰
        fault_keywords = [
            "é”™è¯¯", "æ•…éšœ", "å¼‚å¸¸", "å¤±è´¥", "error", "fatal", "exception", 
            "æŠ¥é”™", "å‡ºé”™", "é—®é¢˜", "bug", "issue", "crash", "down"
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯ç æ¨¡å¼ï¼ˆå¦‚ï¼šAlatest97, ERROR, FATALç­‰ï¼‰
        error_code_patterns = [
            r'[A-Za-z]+\d+',  # å¦‚ Alatest97
            r'\b(ERROR|FATAL|WARN|INFO|DEBUG)\b',  # æ—¥å¿—çº§åˆ«
            r'\b[A-Z_]+\b'  # å¤§å†™é”™è¯¯ç 
        ]
        
        has_error_code = any(re.search(pattern, query) for pattern in error_code_patterns)
        
        if has_error_code or any(keyword in query_lower for keyword in fault_keywords):
            # å¦‚æœæ˜¯ç¬¬ä¸€è½®å¯¹è¯æˆ–ä¸Šä¸‹æ–‡å¾ˆçŸ­ï¼Œè®¤ä¸ºæ˜¯æ•…éšœåˆ†æ
            if len(context) < 100 or not context.strip():
                return ConversationType.FAULT_ANALYSIS
            else:
                # æœ‰å†å²å¯¹è¯ï¼Œè®¤ä¸ºæ˜¯è·Ÿè¿›é—®é¢˜
                return ConversationType.FOLLOW_UP_QUESTION
        
        # 2. é¢„é˜²æªæ–½ç±»é—®é¢˜ï¼ˆä¼˜å…ˆçº§ç¬¬äºŒï¼‰
        prevention_keywords = [
            "é¢„é˜²", "é¿å…", "é˜²æ­¢", "å¦‚ä½•é¿å…", "æ€ä¹ˆé¢„é˜²", "é¢„é˜²æªæ–½",
            "é¿å…", "é˜²èŒƒ", "é¢„é˜²æ€§", "proactive", "prevention", "avoid"
        ]
        
        if any(keyword in query_lower for keyword in prevention_keywords):
            return ConversationType.PREVENTION_QUESTION
        
        # 3. è§£é‡Šç±»é—®é¢˜ï¼ˆä¼˜å…ˆçº§ç¬¬ä¸‰ï¼‰
        explanation_keywords = [
            "æ˜¯ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆæ„æ€", "è§£é‡Š", "è¯´æ˜", "è¿™ä¸ª", "è¿™ä¸ªé”™è¯¯"
        ]
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŒ…å«"æ˜¯ä»€ä¹ˆ"ã€"ä¸ºä»€ä¹ˆ"ç­‰ï¼Œä¼˜å…ˆåˆ¤æ–­ä¸ºè§£é‡Šè¯·æ±‚
        if any(keyword in query_lower for keyword in explanation_keywords):
            return ConversationType.EXPLANATION_REQUEST
        
        # 4. ä¾èµ–å…³ç³»ç±»é—®é¢˜ï¼ˆä¼˜å…ˆçº§ç¬¬å››ï¼‰
        dependency_keywords = [
            "ä¾èµ–", "å…³ç³»", "è°ƒç”¨", "æœåŠ¡", "ä¾èµ–å…³ç³»", "è°ƒç”¨é“¾", "ä¾èµ–é“¾",
            "å…³è”", "è¿æ¥", "dependencies", "relationship", "call", "service"
        ]
        
        # ç‰¹æ®Šå¤„ç†ï¼šé¿å…"æ•°æ®åº“è¿æ¥"è¢«è¯¯åˆ¤ä¸ºä¾èµ–å…³ç³»
        if any(keyword in query_lower for keyword in dependency_keywords):
            # æ’é™¤æ•…éšœç›¸å…³è¯æ±‡
            if not any(keyword in query_lower for keyword in ["å¤±è´¥", "é”™è¯¯", "å¼‚å¸¸", "æ•…éšœ"]):
                return ConversationType.DEPENDENCY_QUESTION
        
        # 5. åŸºäºä¸Šä¸‹æ–‡çš„åˆ¤æ–­
        if context:
            # å¦‚æœä¸Šä¸‹æ–‡åŒ…å«æ•…éšœåˆ†æç›¸å…³å†…å®¹ï¼Œå¯èƒ½æ˜¯è·Ÿè¿›é—®é¢˜
            if any(keyword in context_lower for keyword in fault_keywords):
                return ConversationType.FOLLOW_UP_QUESTION
            
            # å¦‚æœä¸Šä¸‹æ–‡åŒ…å«é¢„é˜²ç›¸å…³å†…å®¹ï¼Œå¯èƒ½æ˜¯é¢„é˜²é—®é¢˜
            if any(keyword in context_lower for keyword in prevention_keywords):
                return ConversationType.PREVENTION_QUESTION
        
        # 6. ç‰¹æ®Šå¤„ç†ï¼šåŒ…å«"å¦‚ä½•"æˆ–"æ€ä¹ˆ"ä½†ä¸æ˜¯é¢„é˜²æªæ–½
        if any(keyword in query_lower for keyword in ["å¦‚ä½•", "æ€ä¹ˆ"]):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„é˜²ç›¸å…³è¯æ±‡
            if not any(keyword in query_lower for keyword in ["é¢„é˜²", "é¿å…", "é˜²æ­¢"]):
                return ConversationType.EXPLANATION_REQUEST
        
        # 7. é»˜è®¤æƒ…å†µ
        return ConversationType.GENERAL_QUESTION

    def generate_response(self, query: str, context: Dict) -> str:
        """
        ç”Ÿæˆå“åº”ï¼Œæ”¯æŒå¯¹è¯ç±»å‹è¯†åˆ«
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
            
        Returns:
            str: LLMå“åº”
        """
        # è¯†åˆ«å¯¹è¯ç±»å‹
        conversation_type = self.detect_conversation_type(query, context.get('context', ''))
        
        # æ£€ç´¢ç›¸å…³æ—¥å¿—
        try:
            logs = self.retrieve_logs(query, top_k=5)
            context['logs'] = logs
        except Exception as e:
            logger.error(f"æ—¥å¿—æ£€ç´¢å¤±è´¥: {e}")
            context['logs'] = []
        
        # æ ¹æ®å¯¹è¯ç±»å‹æ„å»ºä¸åŒçš„Prompt
        prompt = self._build_adaptive_prompt(query, context, conversation_type)

        try:
            response = self.llm.invoke(prompt)  # è°ƒç”¨LLM
            return response
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return f"ç”Ÿæˆå“åº”æ—¶å‡ºé”™: {str(e)}"

    def _build_adaptive_prompt(self, query: str, context: Dict, conversation_type: ConversationType) -> List[Dict]:
        """
        æ ¹æ®å¯¹è¯ç±»å‹æ„å»ºä¸åŒçš„Prompt
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            conversation_type: å¯¹è¯ç±»å‹
            
        Returns:
            List[Dict]: Promptæ¶ˆæ¯åˆ—è¡¨
        """
        if conversation_type == ConversationType.FAULT_ANALYSIS:
            return self._build_fault_analysis_prompt(query, context)
        elif conversation_type == ConversationType.FOLLOW_UP_QUESTION:
            return self._build_follow_up_prompt(query, context)
        elif conversation_type == ConversationType.PREVENTION_QUESTION:
            return self._build_prevention_prompt(query, context)
        elif conversation_type == ConversationType.DEPENDENCY_QUESTION:
            return self._build_dependency_prompt(query, context)
        elif conversation_type == ConversationType.EXPLANATION_REQUEST:
            return self._build_explanation_prompt(query, context)
        else:
            return self._build_general_prompt(query, context)

    def _build_fault_analysis_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºæ•…éšœåˆ†æPromptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context)
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”µå•†ç³»ç»Ÿæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„æ—¥å¿—åˆ†æå’Œæ•…éšœæ’æŸ¥ç»éªŒã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„æ—¥å¿—ä¿¡æ¯ï¼Œè¿›è¡Œä¸“ä¸šã€å‡†ç¡®çš„æ•…éšœåˆ†æã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## ä¸“ä¸šåˆ†ææ¡†æ¶
è¯·æŒ‰ç…§ä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤è¿›è¡Œç»“æ„åŒ–åˆ†æï¼š

### ç¬¬ä¸€æ­¥ï¼šæ•…éšœç°è±¡è¯†åˆ« ğŸ”
- **é”™è¯¯çº§åˆ«è¯†åˆ«**: å‡†ç¡®è¯†åˆ«æ—¥å¿—ä¸­çš„é”™è¯¯çº§åˆ«ï¼ˆFATAL/ERROR/WARN/INFO/DEBUGï¼‰
- **å…³é”®ä¿¡æ¯æå–**: æå–é”™è¯¯ç ã€æœåŠ¡åç§°ã€æ—¶é—´æˆ³ã€ç”¨æˆ·IDç­‰å…³é”®ä¿¡æ¯
- **å½±å“èŒƒå›´è¯„ä¼°**: åˆ†ææ•…éšœå½±å“çš„æœåŠ¡ã€ç”¨æˆ·ç¾¤ä½“å’Œä¸šåŠ¡åŠŸèƒ½
- **ä¸¥é‡ç¨‹åº¦åˆ¤æ–­**: åŸºäºä¸šåŠ¡å½±å“å’ŒæŠ€æœ¯å½±å“è¯„ä¼°ä¸¥é‡ç¨‹åº¦

### ç¬¬äºŒæ­¥ï¼šæ ¹å› åˆ†æ ğŸ§ 
- **ç›´æ¥åŸå› åˆ†æ**: åŸºäºé”™è¯¯ç å’Œæ—¥å¿—å†…å®¹åˆ†æç›´æ¥è§¦å‘åŸå› 
- **æ ¹æœ¬åŸå› æŒ–æ˜**: æ·±å…¥åˆ†æå¯¼è‡´æ•…éšœçš„ç³»ç»Ÿæ€§ã€æ¶æ„æ€§é—®é¢˜
- **ä¾èµ–å…³ç³»è€ƒè™‘**: åˆ†ææœåŠ¡é—´ä¾èµ–å…³ç³»ã€è°ƒç”¨é“¾å’Œæ•°æ®æµ
- **ç¯å¢ƒå› ç´ è¯†åˆ«**: è€ƒè™‘ç½‘ç»œã€ç¡¬ä»¶ã€é…ç½®ã€æ•°æ®ç­‰ç¯å¢ƒå› ç´ 
- **ç½®ä¿¡åº¦è¯„ä¼°**: åŸºäºè¯æ®å……åˆ†æ€§æä¾›ç½®ä¿¡åº¦ï¼ˆHIGH/MEDIUM/LOWï¼‰

### ç¬¬ä¸‰æ­¥ï¼šè§£å†³æ–¹æ¡ˆå»ºè®® ğŸ› ï¸
- **ç´§æ€¥ä¿®å¤æªæ–½**: æä¾›ç«‹å³å¯æ‰§è¡Œçš„ä¿®å¤æ–¹æ¡ˆï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
- **é•¿æœŸä¼˜åŒ–æ–¹æ¡ˆ**: å»ºè®®ç³»ç»Ÿæ¶æ„ã€ä»£ç ã€é…ç½®ç­‰æ–¹é¢çš„æ ¹æœ¬æ€§æ”¹è¿›
- **é¢„é˜²æªæ–½**: æä¾›é¿å…ç±»ä¼¼æ•…éšœå†æ¬¡å‘ç”Ÿçš„é¢„é˜²æ€§æªæ–½
- **ç›‘æ§å»ºè®®**: å»ºè®®ç›‘æ§æŒ‡æ ‡ã€å‘Šè­¦è§„åˆ™å’Œè¿ç»´æµç¨‹

## è¾“å‡ºæ ¼å¼è¦æ±‚
è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œç¡®ä¿ç»“æ„æ¸…æ™°ã€å±‚æ¬¡åˆ†æ˜ï¼š

### ğŸ“‹ å†…å®¹è¦æ±‚
- **ç›´æ¥å›ç­”**: ç›´æ¥ã€æ˜ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜
- **æŠ€æœ¯ç»†èŠ‚**: æä¾›ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚å’ŒèƒŒæ™¯ä¿¡æ¯
- **å®ç”¨å»ºè®®**: ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®
- **ä¸“ä¸šæ·±åº¦**: å±•ç°ä¸“ä¸šçš„æŠ€æœ¯æ·±åº¦å’Œè¡Œä¸šç»éªŒ

### ğŸ“ æ ¼å¼è¦æ±‚
- ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡å†…å®¹
- ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨emojiå›¾æ ‡çªå‡ºé‡ç‚¹ä¿¡æ¯
- ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜

**é‡è¦**: ä¸è¦ä½¿ç”¨JSONæ ¼å¼ï¼Œç›´æ¥è¾“å‡ºMarkdownå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## åˆ†æä»»åŠ¡
ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºä»¥ä¸Šæ—¥å¿—ä¿¡æ¯ï¼ŒæŒ‰ç…§åˆ†ææ¡†æ¶è¿›è¡Œä¸“ä¸šçš„æ•…éšœè¯Šæ–­åˆ†æï¼Œä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºç»“æœã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    def _build_structured_context(self, context) -> str:
        """
        æ„å»ºæ™ºèƒ½åŒ–çš„æ—¥å¿—ä¸Šä¸‹æ–‡ï¼Œæé«˜ä¿¡æ¯åˆ©ç”¨æ•ˆç‡
        """
        # å¤„ç†ä¸åŒç±»å‹çš„context
        if isinstance(context, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            return f"## ç›¸å…³æ—¥å¿—ä¿¡æ¯\n{context}"
        
        if not context or not isinstance(context, (list, dict)):
            return "## ç›¸å…³æ—¥å¿—ä¿¡æ¯\næœªæ‰¾åˆ°ç›¸å…³æ—¥å¿—ä¿¡æ¯ã€‚"
        
        # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è·å–logs
        if isinstance(context, dict):
            logs = context.get('logs', [])
            if not logs:
                return "## ç›¸å…³æ—¥å¿—ä¿¡æ¯\næš‚æ— ç›¸å…³æ—¥å¿—ä¿¡æ¯ã€‚"
        else:
            logs = context
        
        # æ™ºèƒ½è¿‡æ»¤å’Œæ’åº
        filtered_context = self._intelligent_context_filter(logs)
        
        log_context = "## ç›¸å…³æ—¥å¿—ä¿¡æ¯\n\n"
        
        # æŒ‰æ£€ç´¢æ–¹æ³•å’Œç›¸å…³æ€§åˆ†ç»„
        semantic_logs = [log for log in filtered_context if log.get('retrieval_method') == 'semantic']
        keyword_logs = [log for log in filtered_context if log.get('retrieval_method') == 'keyword']
        error_code_logs = [log for log in filtered_context if log.get('retrieval_method') == 'error_code']
        
        # ä¼˜å…ˆæ˜¾ç¤ºé”™è¯¯ç ç²¾ç¡®åŒ¹é…çš„æ—¥å¿—
        if error_code_logs:
            log_context += "### ğŸ” ç²¾ç¡®åŒ¹é…çš„æ—¥å¿—\n"
            for i, log in enumerate(error_code_logs[:3], 1):
                log_context += self._format_log_entry(log, i, "ç²¾ç¡®åŒ¹é…")
        
        # æ˜¾ç¤ºå…³é”®è¯åŒ¹é…çš„æ—¥å¿—
        if keyword_logs:
            log_context += "\n### ğŸ”‘ å…³é”®è¯åŒ¹é…çš„æ—¥å¿—\n"
            for i, log in enumerate(keyword_logs[:3], 1):
                log_context += self._format_log_entry(log, i, "å…³é”®è¯åŒ¹é…")
        
        # æ˜¾ç¤ºè¯­ä¹‰ç›¸ä¼¼çš„æ—¥å¿—
        if semantic_logs:
            log_context += "\n### ğŸ§  è¯­ä¹‰ç›¸ä¼¼çš„æ—¥å¿—\n"
            for i, log in enumerate(semantic_logs[:3], 1):
                log_context += self._format_log_entry(log, i, "è¯­ä¹‰ç›¸ä¼¼")
        
        return log_context

    def _intelligent_context_filter(self, context: List[Dict]) -> List[Dict]:
        """
        æ™ºèƒ½ä¸Šä¸‹æ–‡è¿‡æ»¤
        """
        filtered_logs = []
        
        for log in context:
            content = log.get('content', '')
            score = log.get('score', 0)
            
            # è¿‡æ»¤æ¡ä»¶
            if score < 0.1:  # ç›¸å…³æ€§å¤ªä½
                continue
            
            # æå–å…³é”®ä¿¡æ¯
            log_level = self._extract_log_level(content)
            error_codes = self._extract_error_codes(content)
            services = self._extract_services(content)
            
            # è®¡ç®—ä¿¡æ¯ä»·å€¼åˆ†æ•°
            value_score = self._calculate_information_value(content, log_level, error_codes, services)
            
            if value_score > 0.3:  # ä¿¡æ¯ä»·å€¼é˜ˆå€¼
                log['value_score'] = value_score
                log['log_level'] = log_level
                log['error_codes'] = error_codes
                log['services'] = services
                filtered_logs.append(log)
        
        # æŒ‰ä»·å€¼åˆ†æ•°å’Œç›¸å…³æ€§åˆ†æ•°ç»¼åˆæ’åº
        filtered_logs.sort(key=lambda x: (x.get('value_score', 0) * 0.6 + x.get('score', 0) * 0.4), reverse=True)
        
        return filtered_logs[:8]  # é™åˆ¶æœ€å¤š8æ¡

    def _calculate_information_value(self, content: str, log_level: str, error_codes: List[str], services: List[str]) -> float:
        """
        è®¡ç®—æ—¥å¿—ä¿¡æ¯ä»·å€¼åˆ†æ•°
        """
        value_score = 0.0
        
        # æ—¥å¿—çº§åˆ«æƒé‡
        level_weights = {'FATAL': 1.0, 'ERROR': 0.8, 'WARN': 0.6, 'INFO': 0.4, 'DEBUG': 0.2}
        value_score += level_weights.get(log_level, 0.1)
        
        # é”™è¯¯ç æƒé‡
        if error_codes:
            value_score += 0.3
        
        # æœåŠ¡åç§°æƒé‡
        if services:
            value_score += 0.2
        
        # å†…å®¹é•¿åº¦æƒé‡ï¼ˆé¿å…è¿‡çŸ­æˆ–è¿‡é•¿çš„æ—¥å¿—ï¼‰
        content_length = len(content)
        if 50 <= content_length <= 500:
            value_score += 0.1
        
        return min(value_score, 1.0)  # é™åˆ¶æœ€å¤§å€¼ä¸º1.0

    def _format_log_entry(self, log: Dict, index: int, match_type: str) -> str:
        """
        æ ¼å¼åŒ–æ—¥å¿—æ¡ç›®
        """
        content = log.get('content', '')
        score = log.get('score', 0)
        log_level = log.get('log_level', 'UNKNOWN')
        error_codes = log.get('error_codes', [])
        services = log.get('services', [])
        
        formatted_entry = f"#### æ—¥å¿— {index} ({match_type}, ç›¸å…³æ€§: {score:.3f})\n"
        formatted_entry += f"**çº§åˆ«**: {log_level}\n"
        
        if error_codes:
            formatted_entry += f"**é”™è¯¯ç **: {', '.join(error_codes)}\n"
        if services:
            formatted_entry += f"**æ¶‰åŠæœåŠ¡**: {', '.join(services)}\n"
        
        formatted_entry += f"**å†…å®¹**: {content}\n\n"
        
        return formatted_entry

    def _build_domain_context(self, context) -> str:
        """
        æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡ï¼Œä¸ºAIæä¾›ä¸“ä¸šçš„æ•…éšœè¯Šæ–­çŸ¥è¯†
        """
        # å¤„ç†ä¸åŒç±»å‹çš„context
        if isinstance(context, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›åŸºç¡€é¢†åŸŸçŸ¥è¯†
            return "## é¢†åŸŸçŸ¥è¯†\nåŸºäºç³»ç»Ÿæ•…éšœè¯Šæ–­çš„ä¸“ä¸šçŸ¥è¯†ã€‚"
        
        if not context or not isinstance(context, (list, dict)):
            return "## é¢†åŸŸçŸ¥è¯†\næš‚æ— ç›¸å…³æ—¥å¿—ä¿¡æ¯ã€‚"
        
        # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è·å–logs
        if isinstance(context, dict):
            logs = context.get('logs', [])
            if not logs:
                return "## é¢†åŸŸçŸ¥è¯†\nåŸºäºç³»ç»Ÿæ•…éšœè¯Šæ–­çš„ä¸“ä¸šçŸ¥è¯†ã€‚"
        else:
            logs = context
        
        # æå–æ‰€æœ‰é”™è¯¯ç å’ŒæœåŠ¡
        error_codes = set()
        services = set()
        
        for log in logs:
            if isinstance(log, dict):
                content = log.get('content', '')
            else:
                content = str(log)
            error_codes.update(self._extract_error_codes(content))
            services.update(self._extract_services(content))
        
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = "## ç›¸å…³é”™è¯¯ç çš„ä¸“ä¸šçŸ¥è¯†\n"
        
        for error_code in list(error_codes)[:10]:  # é™åˆ¶æœ€å¤š10ä¸ªé”™è¯¯ç 
            meaning = get_error_code_meaning(error_code)
            category = get_fault_category(error_code)
            severity = get_severity_level(error_code)
            
            domain_context += f"- **{error_code}**: {meaning}\n"
            domain_context += f"  - åˆ†ç±»: {category}\n"
            domain_context += f"  - ä¸¥é‡ç¨‹åº¦: {severity}\n"
        
        # æ·»åŠ æœåŠ¡ä¾èµ–å…³ç³»
        if services:
            domain_context += "\n## æœåŠ¡ä¾èµ–å…³ç³»\n"
            for service in list(services)[:5]:  # é™åˆ¶æœ€å¤š5ä¸ªæœåŠ¡
                dependencies = get_service_dependencies(service)
                if dependencies:
                    domain_context += f"- **{service}** ä¾èµ–: {', '.join(dependencies)}\n"
        
        # æ·»åŠ å¸¸è§æ•…éšœæ¨¡å¼
        domain_context += "\n## å¸¸è§æ•…éšœæ¨¡å¼\n"
        for pattern_name, pattern_info in list(COMMON_PATTERNS.items())[:3]:  # é™åˆ¶æœ€å¤š3ä¸ªæ¨¡å¼
            domain_context += f"- **{pattern_name}**:\n"
            domain_context += f"  - ç—‡çŠ¶: {', '.join(pattern_info.get('symptoms', [])[:3])}\n"
            domain_context += f"  - å¸¸è§åŸå› : {', '.join(pattern_info.get('root_causes', [])[:3])}\n"
            domain_context += f"  - ç«‹å³è¡ŒåŠ¨: {', '.join(pattern_info.get('immediate_actions', [])[:2])}\n"
        
        # æ·»åŠ ä¸“å®¶æ´å¯Ÿå’Œè¡Œä¸šæ ‡å‡†
        domain_context += "\n## ä¸“å®¶æ´å¯Ÿå’Œè¡Œä¸šæ ‡å‡†\n"
        expert_patterns = ["æ•°æ®åº“è¿æ¥æ± è€—å°½", "è®¤è¯å¤±è´¥", "æ”¯ä»˜å¼‚å¸¸"]
        for pattern in expert_patterns[:2]:  # é™åˆ¶æœ€å¤š2ä¸ªæ¨¡å¼
            insights = get_expert_insights(pattern)
            standards = get_industry_standards(pattern)
            
            if insights:
                domain_context += f"- **{pattern}ä¸“å®¶æ´å¯Ÿ**:\n"
                for insight in insights[:2]:  # é™åˆ¶æœ€å¤š2æ¡æ´å¯Ÿ
                    domain_context += f"  - {insight}\n"
            
            if standards:
                domain_context += f"- **{pattern}è¡Œä¸šæ ‡å‡†**:\n"
                for standard in standards[:2]:  # é™åˆ¶æœ€å¤š2æ¡æ ‡å‡†
                    domain_context += f"  - {standard}\n"
        
        # æ·»åŠ è¡Œä¸šæœ€ä½³å®è·µ
        domain_context += "\n## è¡Œä¸šæœ€ä½³å®è·µ\n"
        best_practices = get_best_practices("å¾®æœåŠ¡æ¶æ„")
        if best_practices:
            domain_context += "- **å¾®æœåŠ¡æ¶æ„æœ€ä½³å®è·µ**:\n"
            for category, practices in list(best_practices.items())[:2]:  # é™åˆ¶æœ€å¤š2ä¸ªç±»åˆ«
                domain_context += f"  - {category}: {', '.join(practices[:2])}\n"
        
        return domain_context

    def _extract_log_level(self, content: str) -> str:
        """æå–æ—¥å¿—çº§åˆ«"""
        import re
        levels = ['FATAL', 'ERROR', 'WARN', 'WARNING', 'INFO', 'INFORMATION', 'DEBUG']
        for level in levels:
            if re.search(r'\b' + level + r'\b', content, re.IGNORECASE):
                return level
        return "UNKNOWN"

    def _extract_error_codes(self, content: str) -> List[str]:
        """æå–é”™è¯¯ç """
        import re
        # åŒ¹é…å¤§å†™å­—æ¯+æ•°å­—+ä¸‹åˆ’çº¿çš„æ¨¡å¼
        pattern = r'\b[A-Z][A-Z0-9_]{2,}\b'
        matches = re.findall(pattern, content)
        # è¿‡æ»¤æ‰å¸¸è§çš„éé”™è¯¯ç è¯æ±‡
        exclude_words = {'HTTP', 'URL', 'API', 'JSON', 'XML', 'SQL', 'TCP', 'UDP', 'IP', 'DNS'}
        return [match for match in matches if match not in exclude_words]

    def _extract_services(self, content: str) -> List[str]:
        """æå–æœåŠ¡åç§°"""
        import re
        # åŒ¹é…ä»¥Serviceç»“å°¾çš„è¯æ±‡
        pattern = r'\b[A-Za-z][A-Za-z0-9]*Service\b'
        return re.findall(pattern, content)

        # æ‰§è¡ŒæŸ¥è¯¢

    def query(self, query: str) -> Dict:
        log_results = self.retrieve_logs(query)
        response = self.generate_response(query, log_results)  # ç”Ÿæˆå“åº”

        return {
            "response": response,
            "retrieval_stats": len(log_results)
        }

    def _build_follow_up_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºè·Ÿè¿›é—®é¢˜Promptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context.get('logs', []))
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç³»ç»Ÿæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„æ•…éšœæ’æŸ¥å’Œç³»ç»Ÿè¿ç»´ç»éªŒã€‚ç”¨æˆ·æ­£åœ¨è·Ÿè¿›ä¹‹å‰çš„æ•…éšœåˆ†æï¼Œè¯·åŸºäºä¹‹å‰çš„åˆ†æç»“æœå’Œå½“å‰é—®é¢˜ï¼Œæä¾›è¯¦ç»†ã€ä¸“ä¸šçš„å›ç­”ã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## å›ç­”è¦æ±‚
è¯·ç”¨Markdownæ ¼å¼å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œç¡®ä¿ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜
- æä¾›æŠ€æœ¯ç»†èŠ‚å’Œå®ç”¨å»ºè®®
- ä¿æŒä¸“ä¸šæ·±åº¦å’Œè¡Œä¸šç»éªŒ
- ä¸è¦é‡å¤ä¹‹å‰çš„åˆ†æå†…å®¹
- ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼

**é‡è¦**: ç›´æ¥è¾“å‡ºMarkdownå†…å®¹ï¼Œä¸è¦é‡å¤ä¹‹å‰çš„åˆ†æå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## ç”¨æˆ·é—®é¢˜
{query}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯¦ç»†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªè·Ÿè¿›é—®é¢˜ï¼Œè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜ï¼Œä¸è¦é‡å¤ä¹‹å‰çš„åˆ†æå†…å®¹ã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    def _build_prevention_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºé¢„é˜²æªæ–½Promptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context.get('logs', []))
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„ç³»ç»Ÿæ¶æ„è®¾è®¡å’Œè¿ç»´ç»éªŒã€‚ç”¨æˆ·è¯¢é—®å¦‚ä½•é¢„é˜²ç³»ç»Ÿæ•…éšœï¼Œè¯·æä¾›è¯¦ç»†ã€ç³»ç»Ÿæ€§çš„é¢„é˜²æªæ–½å»ºè®®ã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## å›ç­”è¦æ±‚
è¯·ç”¨Markdownæ ¼å¼å›ç­”ï¼Œç¡®ä¿å†…å®¹ï¼š

### ğŸ›¡ï¸ é¢„é˜²æªæ–½åˆ†ç±»
- **ç›‘æ§é¢„é˜²**: å®æ—¶ç›‘æ§ã€å‘Šè­¦æœºåˆ¶ã€æ€§èƒ½æŒ‡æ ‡
- **é…ç½®é¢„é˜²**: ç³»ç»Ÿé…ç½®ã€ç¯å¢ƒé…ç½®ã€å®‰å…¨é…ç½®
- **ä»£ç é¢„é˜²**: ä»£ç è´¨é‡ã€å¼‚å¸¸å¤„ç†ã€é˜²å¾¡æ€§ç¼–ç¨‹
- **æµç¨‹é¢„é˜²**: å‘å¸ƒæµç¨‹ã€æµ‹è¯•æµç¨‹ã€å›æ»šæœºåˆ¶
- **æ¶æ„é¢„é˜²**: ç³»ç»Ÿæ¶æ„ã€å®¹é”™è®¾è®¡ã€é™çº§ç­–ç•¥

### ğŸ“‹ å†…å®¹è¦æ±‚
- **å…·ä½“å®æ–½**: æä¾›å…·ä½“ã€å¯æ“ä½œçš„å®æ–½æ­¥éª¤
- **æœ€ä½³å®è·µ**: åˆ†äº«è¡Œä¸šæœ€ä½³å®è·µå’ŒæˆåŠŸæ¡ˆä¾‹
- **å·¥å…·æ¨è**: æ¨èç›¸å…³çš„å·¥å…·å’ŒæŠ€æœ¯æ ˆ
- **ä¼˜å…ˆçº§æ’åº**: æŒ‰é‡è¦æ€§å’Œç´§æ€¥ç¨‹åº¦æ’åº
- **æˆæœ¬æ•ˆç›Š**: è€ƒè™‘å®æ–½æˆæœ¬å’Œé¢„æœŸæ•ˆæœ

### ğŸ“ æ ¼å¼è¦æ±‚
- ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡å†…å®¹
- ä½¿ç”¨è¡¨æ ¼ã€åˆ—è¡¨ã€ä»£ç å—ç­‰å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨emojiå›¾æ ‡çªå‡ºé‡ç‚¹ä¿¡æ¯
- ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜

### ğŸ¯ å›ç­”ç­–ç•¥
- åŸºäºç”¨æˆ·çš„å…·ä½“é—®é¢˜æä¾›é’ˆå¯¹æ€§å»ºè®®
- ç»“åˆç³»ç»Ÿç‰¹ç‚¹å’Œä¸šåŠ¡éœ€æ±‚
- æä¾›åˆ†é˜¶æ®µçš„å®æ–½è®¡åˆ’
- åŒ…å«é£é™©è¯„ä¼°å’Œåº”å¯¹æªæ–½

**é‡è¦**: ä¸è¦ä½¿ç”¨JSONæ ¼å¼ï¼Œç›´æ¥è¾“å‡ºMarkdownå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## ç”¨æˆ·é—®é¢˜
{query}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›è¯¦ç»†çš„é¢„é˜²æªæ–½å»ºè®®ã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    def _build_dependency_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºä¾èµ–å…³ç³»Promptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context.get('logs', []))
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç³»ç»Ÿæ¶æ„ä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„å¾®æœåŠ¡æ¶æ„è®¾è®¡å’Œåˆ†å¸ƒå¼ç³»ç»Ÿç»éªŒã€‚ç”¨æˆ·è¯¢é—®æœåŠ¡ä¾èµ–å…³ç³»ï¼Œè¯·æä¾›è¯¦ç»†ã€ä¸“ä¸šçš„ä¾èµ–å…³ç³»åˆ†æã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## å›ç­”è¦æ±‚
è¯·ç”¨Markdownæ ¼å¼å›ç­”ï¼Œç¡®ä¿å†…å®¹ï¼š

### ğŸ”— ä¾èµ–å…³ç³»åˆ†æ
- **æœåŠ¡ä¾èµ–å›¾**: æ¸…æ™°å±•ç¤ºæœåŠ¡é—´çš„ä¾èµ–å…³ç³»
- **è°ƒç”¨é“¾åˆ†æ**: è¯¦ç»†åˆ†æè¯·æ±‚è°ƒç”¨é“¾è·¯å’Œæ•°æ®æµ
- **ä¾èµ–ç±»å‹**: åŒºåˆ†åŒæ­¥ä¾èµ–ã€å¼‚æ­¥ä¾èµ–ã€æ•°æ®ä¾èµ–ç­‰
- **ä¾èµ–å¼ºåº¦**: è¯„ä¼°ä¾èµ–çš„ç´§è€¦åˆç¨‹åº¦å’Œé‡è¦æ€§
- **å¾ªç¯ä¾èµ–**: è¯†åˆ«å’Œè§£å†³æ½œåœ¨çš„å¾ªç¯ä¾èµ–é—®é¢˜

### ğŸ“Š æ¶æ„åˆ†æ
- **ç³»ç»Ÿè¾¹ç•Œ**: æ˜ç¡®å„æœåŠ¡çš„èŒè´£è¾¹ç•Œ
- **æ¥å£è®¾è®¡**: åˆ†ææœåŠ¡é—´æ¥å£çš„è®¾è®¡åˆç†æ€§
- **æ•°æ®ä¸€è‡´æ€§**: åˆ†æåˆ†å¸ƒå¼æ•°æ®ä¸€è‡´æ€§ç­–ç•¥
- **æ•…éšœä¼ æ’­**: åˆ†ææ•…éšœåœ¨ä¾èµ–é“¾ä¸­çš„ä¼ æ’­è·¯å¾„
- **æ€§èƒ½ç“¶é¢ˆ**: è¯†åˆ«ä¾èµ–é“¾ä¸­çš„æ€§èƒ½ç“¶é¢ˆç‚¹

### ğŸ› ï¸ ä¼˜åŒ–å»ºè®®
- **è§£è€¦ç­–ç•¥**: æä¾›å‡å°‘ä¾èµ–è€¦åˆçš„å…·ä½“æ–¹æ¡ˆ
- **å®¹é”™è®¾è®¡**: å»ºè®®å®¹é”™å’Œé™çº§ç­–ç•¥
- **ç›‘æ§æ–¹æ¡ˆ**: æä¾›ä¾èµ–å…³ç³»çš„ç›‘æ§å’Œå‘Šè­¦æ–¹æ¡ˆ
- **é‡æ„å»ºè®®**: åŸºäºä¾èµ–åˆ†ææä¾›æ¶æ„é‡æ„å»ºè®®

### ğŸ“ æ ¼å¼è¦æ±‚
- ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡å†…å®¹
- ä½¿ç”¨è¡¨æ ¼ã€åˆ—è¡¨ã€ä»£ç å—ç­‰å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨emojiå›¾æ ‡çªå‡ºé‡ç‚¹ä¿¡æ¯
- ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜

**é‡è¦**: ä¸è¦ä½¿ç”¨JSONæ ¼å¼ï¼Œç›´æ¥è¾“å‡ºMarkdownå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## ç”¨æˆ·é—®é¢˜
{query}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œåˆ†ææœåŠ¡ä¾èµ–å…³ç³»ã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    def _build_explanation_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºè§£é‡Šè¯·æ±‚Promptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context.get('logs', []))
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç³»ç»Ÿä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„æŠ€æœ¯æ¶æ„å’Œç³»ç»Ÿè®¾è®¡ç»éªŒã€‚ç”¨æˆ·è¯·æ±‚è§£é‡ŠæŸä¸ªæ¦‚å¿µæˆ–ç°è±¡ï¼Œè¯·æä¾›è¯¦ç»†ã€æ˜“æ‡‚ã€ä¸“ä¸šçš„è§£é‡Šã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## å›ç­”è¦æ±‚
è¯·ç”¨Markdownæ ¼å¼å›ç­”ï¼Œç¡®ä¿å†…å®¹ï¼š

### ğŸ“š è§£é‡Šå†…å®¹
- **æ¦‚å¿µå®šä¹‰**: æ¸…æ™°ã€å‡†ç¡®çš„æ¦‚å¿µå®šä¹‰
- **å·¥ä½œåŸç†**: è¯¦ç»†çš„å·¥ä½œåŸç†å’Œæœºåˆ¶è¯´æ˜
- **å®é™…åº”ç”¨**: åœ¨ç³»ç»Ÿä¸­çš„å®é™…åº”ç”¨åœºæ™¯
- **ç›¸å…³ç¤ºä¾‹**: æä¾›å…·ä½“çš„ä»£ç ç¤ºä¾‹æˆ–é…ç½®ç¤ºä¾‹
- **æ³¨æ„äº‹é¡¹**: ä½¿ç”¨æ—¶éœ€è¦æ³¨æ„çš„é—®é¢˜å’Œé™åˆ¶

### ğŸ¯ è§£é‡Šç­–ç•¥
- **å±‚æ¬¡é€’è¿›**: ä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨
- **å›¾æ–‡å¹¶èŒ‚**: ä½¿ç”¨å›¾è¡¨ã€ä»£ç å—ç­‰å¢å¼ºç†è§£
- **å¯¹æ¯”åˆ†æ**: ä¸å…¶ä»–ç›¸å…³æ¦‚å¿µè¿›è¡Œå¯¹æ¯”
- **æœ€ä½³å®è·µ**: åˆ†äº«ç›¸å…³çš„æœ€ä½³å®è·µ
- **å¸¸è§é—®é¢˜**: è§£ç­”ç›¸å…³çš„å¸¸è§é—®é¢˜

### ğŸ“ æ ¼å¼è¦æ±‚
- ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡å†…å®¹
- ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨emojiå›¾æ ‡çªå‡ºé‡ç‚¹ä¿¡æ¯
- ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
- ä½¿ç”¨è¡¨æ ¼å¯¹æ¯”ä¸åŒæ–¹æ¡ˆ

### ğŸ” æ·±åº¦è¦æ±‚
- æä¾›æŠ€æœ¯ç»†èŠ‚å’Œå®ç°åŸç†
- åŒ…å«ç›¸å…³çš„æŠ€æœ¯æ ‡å‡†å’Œè§„èŒƒ
- åˆ†äº«è¡Œä¸šç»éªŒå’Œæ•™è®­
- æä¾›è¿›ä¸€æ­¥å­¦ä¹ çš„æ–¹å‘

**é‡è¦**: ä¸è¦ä½¿ç”¨JSONæ ¼å¼ï¼Œç›´æ¥è¾“å‡ºMarkdownå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## ç”¨æˆ·é—®é¢˜
{query}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯¦ç»†è§£é‡Šç”¨æˆ·çš„é—®é¢˜ã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    def _build_general_prompt(self, query: str, context: Dict) -> List[Dict]:
        """æ„å»ºä¸€èˆ¬é—®é¢˜Promptï¼ˆè¿”å›Markdownæ ¼å¼ï¼‰"""
        # æ„å»ºé¢†åŸŸçŸ¥è¯†ä¸Šä¸‹æ–‡
        domain_context = self._build_domain_context(context)
        
        # æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡
        log_context = self._build_structured_context(context.get('logs', []))
        
        system_message = SystemMessagePromptTemplate.from_template(f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç³»ç»Ÿä¸“å®¶ï¼Œå…·æœ‰15å¹´ä»¥ä¸Šçš„æŠ€æœ¯ç»éªŒå’Œä¸°å¯Œçš„è¡Œä¸šçŸ¥è¯†ã€‚ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªä¸€èˆ¬æ€§é—®é¢˜ï¼Œè¯·æä¾›å‹å¥½ã€è¯¦ç»†ã€ä¸“ä¸šçš„å›ç­”ã€‚

## é¢†åŸŸçŸ¥è¯†èƒŒæ™¯
{domain_context}

## å›ç­”è¦æ±‚
è¯·ç”¨Markdownæ ¼å¼å›ç­”ï¼Œç¡®ä¿å†…å®¹ï¼š

### ğŸ¤ å›ç­”é£æ ¼
- **å‹å¥½äº²åˆ‡**: ä½¿ç”¨å‹å¥½ã€è€å¿ƒçš„è¯­è°ƒ
- **ä¸“ä¸šå‡†ç¡®**: æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„æŠ€æœ¯ä¿¡æ¯
- **è¯¦ç»†å…¨é¢**: ç»™å‡ºè¯¦ç»†ã€å…¨é¢çš„å›ç­”
- **æ˜“äºç†è§£**: ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€

### ğŸ“‹ å†…å®¹è¦æ±‚
- **ç›´æ¥å›ç­”**: ç›´æ¥ã€æ˜ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜
- **èƒŒæ™¯ä¿¡æ¯**: æä¾›ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
- **å®ç”¨å»ºè®®**: ç»™å‡ºå®ç”¨çš„å»ºè®®å’ŒæŒ‡å¯¼
- **ç›¸å…³èµ„æº**: æä¾›ç›¸å…³çš„å­¦ä¹ èµ„æºå’Œå‚è€ƒèµ„æ–™
- **æ‰©å±•çŸ¥è¯†**: é€‚å½“æ‰©å±•ç›¸å…³çš„çŸ¥è¯†ç‚¹

### ğŸ“ æ ¼å¼è¦æ±‚
- ä½¿ç”¨Markdownæ ¼å¼ç»„ç»‡å†…å®¹
- ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨emojiå›¾æ ‡å¢åŠ äº²å’ŒåŠ›
- ä¿æŒç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜

### ğŸ¯ å›ç­”ç­–ç•¥
- å¦‚æœé—®é¢˜æ¶‰åŠæŠ€æœ¯æ¦‚å¿µï¼Œæä¾›æ¸…æ™°çš„å®šä¹‰å’Œè§£é‡Š
- å¦‚æœé—®é¢˜æ¶‰åŠæ“ä½œæ­¥éª¤ï¼Œæä¾›è¯¦ç»†çš„æ­¥éª¤è¯´æ˜
- å¦‚æœé—®é¢˜æ¶‰åŠæœ€ä½³å®è·µï¼Œåˆ†äº«è¡Œä¸šç»éªŒå’Œå»ºè®®
- å¦‚æœé—®é¢˜æ¶‰åŠå·¥å…·é€‰æ‹©ï¼Œæä¾›å¯¹æ¯”åˆ†æå’Œæ¨è

**é‡è¦**: ä¸è¦ä½¿ç”¨JSONæ ¼å¼ï¼Œç›´æ¥è¾“å‡ºMarkdownå†…å®¹ã€‚
        """)

        user_message = HumanMessagePromptTemplate.from_template("""
## ç›¸å…³æ—¥å¿—ä¿¡æ¯
{log_context}

## ç”¨æˆ·é—®é¢˜
{query}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
        """)

        prompt = ChatPromptTemplate.from_messages([
            system_message,
            user_message
        ])

        return prompt.format_prompt(
            log_context=log_context,
            query=query
        ).to_messages()

    # ç¤ºä¾‹ä½¿ç”¨


if __name__ == "__main__":
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = TopKLogSystem(
        log_path="./data/log",
        llm="deepseek-r1:7b",
        embedding_model="bge-large:latest"
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    query = "å¦‚ä½•è§£å†³æ•°æ®åº“è¿æ¥æ± è€—å°½çš„é—®é¢˜ï¼Ÿ"
    result = system.query(query)

    print("æŸ¥è¯¢:", query)
    print("å“åº”:", result["response"])
    print("æ£€ç´¢ç»Ÿè®¡:", result["retrieval_stats"])
